{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contributor: Sudesh Kumar Santhosh Kumar\n",
    "- Email: sudeshkumar.santhoshkumar@lexisnexis.com\n",
    "- Date: 21st June, 2023\n",
    "\n",
    "Description:  This Notebook will show you how to fine-tune BERT for multi-class text classification tasks, meaning that there are more than just two classes in the dataset. We'll be using the 20 Newsgroups dataset, which is a test classification dataset with 20 different classes. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multi-Label vs. Multi-Class**\n",
    "\n",
    "It is important to distinguish between \"Multi-Class\" and \"Multi-Label\" as they pertain to different types of tasks and are handled differently.\n",
    "\n",
    "In \"Multi-Label\" classification, documents can be assigned multiple labels. This means that a document may have several appropriate tags or categories associated with it. For instance, consider a system that suggests tags for documents where multiple tags may be relevant.\n",
    "\n",
    "On the other hand, \"Multi-Class\" classification applies when each document is assigned only one category. If there are only two possible categories, it is known as \"Binary\" classification. If there are more than two categories, it is referred to as \"Multi-Class\" classification. In this scenario, each document is assigned to a single category, without the possibility of multiple labels.\n",
    "\n",
    "By understanding these distinctions, we can appropriately handle and address the requirements of each type of classification task."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Pre-requisites and Installation\n",
    "---------------------------------\n",
    "If you're using this notebook on Google Colab, Don't forget to uncomment the following cell to install transformers library into the notebook. If you're using this notebook on your local machine through VS Code or Jupyter notebook, you need to do a \"pip install -r requirements.txt\" before running the following set of code blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all necessary libraries\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I - Dataset & Tokenization\n",
    "---------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU!\n"
     ]
    }
   ],
   "source": [
    "# Checking if there is a GPU Available.\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    device = torch.device((\"cuda\"))\n",
    "    print(f\"There are {torch.cuda.device_count()} available.\")\n",
    "    print(f\"We will use the GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "else:\n",
    "    print(\"No GPU available, using the CPU!\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
